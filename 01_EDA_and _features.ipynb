# Capstone Project: SME Loan Pre-Screen - Right-First-Time Applications
# Notebook 1: Exploratory Data Analysis (EDA) and Feature Engineering

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
import pickle

# --- Configuration ---
# *** CRITICAL: VERIFY THIS PATH ***
DATA_FILE = 'data/SME Loan Pre-Screen_Right-First-Time Applications.xlsx - Loan Application DataSet.csv'
RANDOM_SEED = 42

# --- 1. Load and Initial Cleaning (ROBUST LOADING) ---
print("Loading data...")
try:
    # Use read_csv. Skip the initial empty row (skiprows=1) and use the next row as header (header=0).
    # Use the default comma separator.
    df = pd.read_csv(DATA_FILE, skiprows=1, header=0, encoding='utf-8')
    
    # Drop the initial, unnamed column that appears to be an extra index column from the export
    if df.columns[0].startswith('Unnamed:'):
        df = df.drop(df.columns[0], axis=1)

    print(f"Successfully loaded data from {DATA_FILE}")
except Exception as e:
    print(f"CRITICAL ERROR LOADING DATA. Check path and file format.")
    print(f"ERROR DETAILS: {e}")
    exit()

# Rename columns for easier access (based on your dataset)
df.columns = ['S_No', 'Applicant_ID', 'Industry', 'Loan_Amount_Requested', 
              'Loan_Category', 'Applicant_Category', 'Income_Doc_Submitted', 
              'KYC_Submitted', 'Business_Proof_Submitted']

# Convert document columns to a consistent format (1 for Yes, 0 for No)
doc_cols = ['Income_Doc_Submitted', 'KYC_Submitted', 'Business_Proof_Submitted']
for col in doc_cols:
    df[col] = df[col].replace({'Yes': 1, 'No': 0})

# --- Error Check: Remove any row where S_No is missing (due to blank lines in CSV) ---
df = df.dropna(subset=['S_No'])

print("\nInitial Data Head (after cleaning):")
print(df.head())
print("-" * 50)


# --- 2. Data Cleaning and Target Definition ---

# Define the target variable: 'is_right_first_time'
# RFT is 1 if all three main documents are submitted.
df['is_right_first_time'] = np.where(
    (df['Income_Doc_Submitted'] == 1) & 
    (df['KYC_Submitted'] == 1) & 
    (df['Business_Proof_Submitted'] == 1), 
    1, 0)

# Check the baseline RFT Rate
baseline_rft_rate = df['is_right_first_time'].mean()
print(f"Baseline Right-First-Time (RFT) Rate: {baseline_rft_rate:.2%}")
print("-" * 50)


# --- 3. Exploratory Data Analysis (EDA) ---

# A. RFT Rate by Applicant's Industry (Identifying areas for targeted guidance)
rft_by_industry = df.groupby('Industry')['is_right_first_time'].mean().sort_values()
print("RFT Rate by Applicant's Industry:")
print(rft_by_industry)

plt.figure(figsize=(8, 5))
sns.barplot(x=rft_by_industry.index, y=rft_by_industry.values, palette="Pastel1")
plt.title('RFT Rate by Industry (Lower means more guidance needed)')
plt.ylabel('RFT Rate')
plt.xlabel('Industry')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
# [attachment_0](attachment)

# B. RFT Rate by Applicant's Category (Identifying the Eligibility Gate)
rft_by_category = df.groupby('Applicant_Category')['is_right_first_time'].mean().sort_values()
print("\nRFT Rate by Applicant's Category (Critical for Eligibility Gate):")
print(rft_by_category)

plt.figure(figsize=(8, 5))
sns.barplot(x=rft_by_category.index, y=rft_by_category.values, palette="Reds_d")
plt.title('RFT Rate by Applicant Category (Bottleneck Identification)')
plt.ylabel('RFT Rate')
plt.xlabel('Applicant Category')
plt.show()
# 

# C. Impact on RFT Rate based on Missing Documents 
rft_reduction = {}
for col in doc_cols:
    missing_rft = df[df[col] == 0]['is_right_first_time'].mean()
    # Reduction is how much the RFT rate drops compared to the baseline when this document is missing.
    reduction = baseline_rft_rate - missing_rft 
    rft_reduction[col] = reduction

doc_rft_series = pd.Series(rft_reduction).sort_values(ascending=False)
print("\nImpact on RFT Rate when a Document is Missing (Most critical first):")
print(doc_rft_series)


# --- 4. Feature Engineering (Preparing data for ML) ---

# Features to use: Industry, Applicant_
